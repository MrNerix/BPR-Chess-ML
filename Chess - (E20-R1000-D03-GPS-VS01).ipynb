{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import asyncio\n",
    "import chess\n",
    "import chess.engine\n",
    "import chess.pgn\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "\n",
    "from chess import Board\n",
    "from chess.pgn import Game\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "id                0\n",
      "rated             0\n",
      "created_at        0\n",
      "last_move_at      0\n",
      "turns             0\n",
      "victory_status    0\n",
      "winner            0\n",
      "increment_code    0\n",
      "white_id          0\n",
      "white_rating      0\n",
      "black_id          0\n",
      "black_rating      0\n",
      "moves             0\n",
      "opening_eco       0\n",
      "opening_name      0\n",
      "opening_ply       0\n",
      "dtype: int64\n",
      "Total number of games: 20058\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('games.csv')\n",
    "\n",
    "# Count missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Droping rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Display mach count\n",
    "print(f\"Total number of games: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games with white rating >= 1000: 19811\n"
     ]
    }
   ],
   "source": [
    "# Only keep games with a white rating of at least 1000\n",
    "df = df[df['white_rating'] >= 1000]\n",
    "# Displau mach count after filtering\n",
    "print(f\"Number of games with white rating >= 1000: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Saved 19811 games to 'games.pgn'\n"
     ]
    }
   ],
   "source": [
    "# Converting the Lichess-style millisecond timestamp into 'YYYY.MM.DD'\n",
    "df['Date'] = pd.to_datetime(df['created_at'], unit='ms').dt.strftime('%Y.%m.%d')\n",
    "\n",
    "# Function to convert a DataFrame row into a PGN-formatted string\n",
    "def row_to_pgn(row):\n",
    "    game = chess.pgn.Game()\n",
    "\n",
    "    # --- Headers ---\n",
    "    game.headers[\"Event\"]   = row[\"id\"]\n",
    "    game.headers[\"Site\"]    = \"https://lichess.org\"\n",
    "    game.headers[\"Date\"]    = row[\"Date\"]\n",
    "    game.headers[\"Round\"]   = \"?\"\n",
    "    game.headers[\"White\"]   = f\"{row['white_id']} ({int(row['white_rating'])})\"\n",
    "    game.headers[\"Black\"]   = f\"{row['black_id']} ({int(row['black_rating'])})\"\n",
    "    game.headers[\"Result\"]  = row[\"winner\"] if pd.notna(row[\"winner\"]) else \"*\"\n",
    "    game.headers[\"ECO\"]     = row.get(\"opening_eco\", \"\")\n",
    "    game.headers[\"Opening\"] = row.get(\"opening_name\", \"\")\n",
    "\n",
    "    # --- Moves ---\n",
    "    board = game.board()\n",
    "    node  = game\n",
    "    # Split the moves by space and parse each SAN move\n",
    "    # The moves are expected to be in Standard Algebraic Notation (SAN)\n",
    "    for san in row[\"moves\"].split():\n",
    "        move = board.parse_san(san)\n",
    "        node = node.add_variation(move)\n",
    "        board.push(move)\n",
    "\n",
    "    # --- Export PGN ---\n",
    "    exporter = chess.pgn.StringExporter(headers=True, variations=False, comments=False)\n",
    "    return game.accept(exporter)\n",
    "\n",
    "# Write all games into one PGN file\n",
    "output_path = \"games.pgn\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as out:\n",
    "    for _, row in df.iterrows():\n",
    "        out.write(row_to_pgn(row))\n",
    "        out.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(f\"✔️ Saved {len(df)} games to '{output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1884 unique moves (including castle & promotions).\n"
     ]
    }
   ],
   "source": [
    "# Mapping moves to integers\n",
    "def build_full_move_mapping(pgn_path):\n",
    "    moves = set()\n",
    "    with open(pgn_path) as f:\n",
    "        while True:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            if game is None:\n",
    "                break\n",
    "            board = game.board()\n",
    "            for mv in game.mainline_moves():\n",
    "                board.push(mv)\n",
    "                moves.add(mv.uci())\n",
    "    sorted_moves = sorted(moves)\n",
    "    int_to_move = {i:uci for i, uci in enumerate(sorted_moves)}\n",
    "    move_to_int = {uci:i for i, uci in int_to_move.items()}\n",
    "    return move_to_int, int_to_move\n",
    "\n",
    "move_to_int, int_to_move = build_full_move_mapping(\"games.pgn\")\n",
    "\n",
    "print(f\"Found {len(int_to_move)} unique moves (including castle & promotions).\")\n",
    "# Save to JSON for later reuse:\n",
    "with open(\"full_move_mapping_1000.json\",\"w\") as f:\n",
    "    # JSON keys must be strings\n",
    "    json.dump({str(i): m for i,m in int_to_move.items()}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19811 games.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "# Open the PGN file\n",
    "pgn_path = \"games.pgn\"\n",
    "pgn = open(pgn_path, encoding=\"utf-8\")\n",
    "\n",
    "# Parse all games into a list\n",
    "games = []\n",
    "while True:\n",
    "    game = chess.pgn.read_game(pgn)\n",
    "    if game is None:\n",
    "        break\n",
    "    games.append(game)\n",
    "pgn.close()\n",
    "\n",
    "print(f\"Loaded {len(games)} games.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix representation of the board\n",
    "def board_to_matrix(board: Board):\n",
    "    # 8x8 for the board, 12 for the piece types (6 white + 6 black)\n",
    "    # Initialize a 3D numpy array with zeros\n",
    "    matrix = np.zeros((8, 8, 12))\n",
    "    piece_map = board.piece_map()\n",
    "    for square, piece in piece_map.items():\n",
    "        # Convert square index to row and column\n",
    "        row, col = divmod(square, 8)\n",
    "        # Map piece type and color to the matrix\n",
    "        piece_type = piece.piece_type - 1\n",
    "        # White pieces are 0-5, black pieces are 6-11\n",
    "        piece_color = 0 if piece.color else 6\n",
    "        matrix[row, col, piece_type + piece_color] = 1\n",
    "    return matrix\n",
    "\n",
    "#\n",
    "def create_input_with_phase(games):\n",
    "    \"\"\"\n",
    "    Returns three parallel lists:\n",
    "      X      = list of board_to_matrix(board) at each ply\n",
    "      y      = list of UCI strings of the moves played\n",
    "      phases = list of 1-based ply numbers\n",
    "    \"\"\"\n",
    "    # Initialize lists to hold the data\n",
    "    X, y, phases = [], [], []\n",
    "    for game in games:\n",
    "        board = game.board()\n",
    "        for ply, move in enumerate(game.mainline_moves(), start=1):\n",
    "            X.append(board_to_matrix(board))\n",
    "            y.append(move.uci())\n",
    "            phases.append(ply)\n",
    "            board.push(move)\n",
    "    return X, y, phases\n",
    "\n",
    "\n",
    "# Create input for neural network training\n",
    "def create_input_for_nn(games):\n",
    "    X = []\n",
    "    y = []\n",
    "    for game in games:\n",
    "        board = game.board()\n",
    "        for move in game.mainline_moves():\n",
    "            X.append(board_to_matrix(board))\n",
    "            y.append(move.uci())\n",
    "            board.push(move)\n",
    "    return X, y\n",
    "\n",
    "# Load the mapping\n",
    "with open(\"full_move_mapping_1000.json\") as f:\n",
    "    raw = json.load(f)\n",
    "int_to_move = {int(k):v for k,v in raw.items()}\n",
    "move_to_int = {v:k for k,v in int_to_move.items()}\n",
    "\n",
    "# Number of moves in policy head\n",
    "N_moves = len(int_to_move)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load positions + ply counts\n",
    "X_all, y_all, phases = create_input_with_phase(games)\n",
    "\n",
    "# Bucket by phase\n",
    "buckets = {'opening': [], 'middlegame': [], 'endgame': []}\n",
    "for board_mat, uci, ply in zip(X_all, y_all, phases):\n",
    "    if   ply <= 20:\n",
    "        buckets['opening'].append((board_mat, uci))\n",
    "    elif ply <= 60:\n",
    "        buckets['middlegame'].append((board_mat, uci))\n",
    "    else:\n",
    "        buckets['endgame'].append((board_mat, uci))\n",
    "\n",
    "# Oversample endgames to 25% of total\n",
    "total      = len(X_all)\n",
    "target_end = int(total * 0.25)\n",
    "combined   = (\n",
    "    buckets['opening']\n",
    "  + buckets['middlegame']\n",
    "  + random.choices(buckets['endgame'], k=target_end)\n",
    ")\n",
    "\n",
    "# Shuffle & unzip back into X_bal, y_bal\n",
    "random.shuffle(combined)\n",
    "X_bal, y_bal = zip(*combined)\n",
    "X_bal, y_bal = list(X_bal), list(y_bal)\n",
    "\n",
    "# One-hot encode balanced labels\n",
    "y_idxs  = [move_to_int[uci] for uci in y_bal]\n",
    "y_train = to_categorical(y_idxs, num_classes=N_moves)\n",
    "\n",
    "# Convert features to NumPy\n",
    "X_train = np.array(X_bal, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EarlyStopping callback\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1884</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">484,188</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m6,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1884\u001b[0m)           │       \u001b[38;5;34m484,188\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,564</span> (4.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,089,564\u001b[0m (4.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,089,564</span> (4.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,089,564\u001b[0m (4.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5ms/step - accuracy: 0.0813 - loss: 5.6994 - val_accuracy: 0.1523 - val_loss: 4.5277\n",
      "Epoch 2/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 5ms/step - accuracy: 0.1304 - loss: 4.7741 - val_accuracy: 0.1635 - val_loss: 4.2733\n",
      "Epoch 3/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 5ms/step - accuracy: 0.1392 - loss: 4.5974 - val_accuracy: 0.1701 - val_loss: 4.1577\n",
      "Epoch 4/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 5ms/step - accuracy: 0.1432 - loss: 4.5143 - val_accuracy: 0.1706 - val_loss: 4.0822\n",
      "Epoch 5/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 5ms/step - accuracy: 0.1454 - loss: 4.4621 - val_accuracy: 0.1731 - val_loss: 4.0453\n",
      "Epoch 6/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 5ms/step - accuracy: 0.1473 - loss: 4.4199 - val_accuracy: 0.1733 - val_loss: 4.0175\n",
      "Epoch 7/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - accuracy: 0.1480 - loss: 4.3960 - val_accuracy: 0.1739 - val_loss: 3.9984\n",
      "Epoch 8/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5ms/step - accuracy: 0.1481 - loss: 4.3776 - val_accuracy: 0.1745 - val_loss: 3.9817\n",
      "Epoch 9/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5ms/step - accuracy: 0.1488 - loss: 4.3655 - val_accuracy: 0.1737 - val_loss: 3.9820\n",
      "Epoch 10/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5ms/step - accuracy: 0.1488 - loss: 4.3640 - val_accuracy: 0.1725 - val_loss: 3.9803\n",
      "Epoch 11/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 5ms/step - accuracy: 0.1483 - loss: 4.3659 - val_accuracy: 0.1742 - val_loss: 3.9895\n",
      "Epoch 12/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5ms/step - accuracy: 0.1491 - loss: 4.3622 - val_accuracy: 0.1733 - val_loss: 3.9785\n",
      "Epoch 13/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5ms/step - accuracy: 0.1473 - loss: 4.3680 - val_accuracy: 0.1694 - val_loss: 4.0184\n",
      "Epoch 14/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5ms/step - accuracy: 0.1465 - loss: 4.3787 - val_accuracy: 0.1719 - val_loss: 3.9795\n",
      "Epoch 15/20\n",
      "\u001b[1m17410/17410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 5ms/step - accuracy: 0.1457 - loss: 4.3894 - val_accuracy: 0.1689 - val_loss: 4.0108\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(8, 8, 12)),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(N_moves, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "model.save(\"models/TF_20EPOCHS_WR1000_map.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_move = dict(zip(move_to_int.values(), move_to_int.keys()))\n",
    "\n",
    "def predict_next_move(board):\n",
    "    board_matrix = board_to_matrix(board).reshape(1, 8, 8, 12)\n",
    "    predictions = model.predict(board_matrix)[0]\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_moves_uci = [move.uci() for move in legal_moves]\n",
    "    sorted_indices = np.argsort(predictions)[::-1]\n",
    "    for move_index in sorted_indices:\n",
    "        move = int_to_move[move_index]\n",
    "        if move in legal_moves_uci:\n",
    "            return move\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = Board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board before prediction:\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\n",
      "Predicted move: e2e4\n",
      "Board after prediction:\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the board before prediction\n",
    "print(\"Board before prediction:\")\n",
    "print(board)\n",
    "\n",
    "# Predict and make the move\n",
    "next_move = predict_next_move(board)\n",
    "board.push_uci(next_move)\n",
    "\n",
    "# Display the board after prediction\n",
    "print(\"\\nPredicted move:\", next_move)\n",
    "print(\"Board after prediction:\")\n",
    "print(board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Event \"?\"]\n",
      "[Site \"?\"]\n",
      "[Date \"????.??.??\"]\n",
      "[Round \"?\"]\n",
      "[White \"?\"]\n",
      "[Black \"?\"]\n",
      "[Result \"*\"]\n",
      "\n",
      "1. e4 *\n"
     ]
    }
   ],
   "source": [
    "print(str(Game.from_board(board)))\n",
    "\n",
    "game = chess.pgn.Game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Saved 20058 games to 'games.pgn'\n",
      "Loaded 20058 games.\n"
     ]
    }
   ],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv('games.csv')\n",
    "df.count()\n",
    "\n",
    "# Convert the Lichess-style millisecond timestamp into 'YYYY.MM.DD'\n",
    "df['Date'] = pd.to_datetime(df['created_at'], unit='ms').dt.strftime('%Y.%m.%d')\n",
    "\n",
    "def row_to_pgn(row):\n",
    "    \"\"\"Turn a DataFrame row into a PGN-formatted string.\"\"\"\n",
    "    game = chess.pgn.Game()\n",
    "\n",
    "    # --- Headers ---\n",
    "    game.headers[\"Event\"]   = row[\"id\"]\n",
    "    game.headers[\"Site\"]    = \"https://lichess.org\"\n",
    "    game.headers[\"Date\"]    = row[\"Date\"]\n",
    "    game.headers[\"Round\"]   = \"?\"\n",
    "    game.headers[\"White\"]   = f\"{row['white_id']} ({int(row['white_rating'])})\"\n",
    "    game.headers[\"Black\"]   = f\"{row['black_id']} ({int(row['black_rating'])})\"\n",
    "    game.headers[\"Result\"]  = row[\"winner\"] if pd.notna(row[\"winner\"]) else \"*\"\n",
    "    game.headers[\"ECO\"]     = row.get(\"opening_eco\", \"\")\n",
    "    game.headers[\"Opening\"] = row.get(\"opening_name\", \"\")\n",
    "\n",
    "    # --- Moves ---\n",
    "    board = game.board()\n",
    "    node  = game\n",
    "    for san in row[\"moves\"].split():\n",
    "        move = board.parse_san(san)\n",
    "        node = node.add_variation(move)\n",
    "        board.push(move)\n",
    "\n",
    "    # --- Export PGN ---\n",
    "    exporter = chess.pgn.StringExporter(headers=True, variations=False, comments=False)\n",
    "    return game.accept(exporter)\n",
    "\n",
    "# Write all games into one PGN file\n",
    "output_path = \"games.pgn\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as out:\n",
    "    for _, row in df.iterrows():\n",
    "        out.write(row_to_pgn(row))\n",
    "        out.write(\"\\n\\n\")\n",
    "\n",
    "print(f\"✔️ Saved {len(df)} games to '{output_path}'\")\n",
    "\n",
    "\n",
    "# Open the PGN file\n",
    "pgn_path = \"games.pgn\"\n",
    "pgn = open(pgn_path, encoding=\"utf-8\")\n",
    "\n",
    "# Parse all games into a list\n",
    "games = []\n",
    "while True:\n",
    "    game = chess.pgn.read_game(pgn)\n",
    "    if game is None:\n",
    "        break\n",
    "    games.append(game)\n",
    "pgn.close()\n",
    "\n",
    "print(f\"Loaded {len(games)} games.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded mapping with 1884 moves → matches model outputs.\n",
      "Loaded 191573 total positions from your PGN.\n",
      "Down-sampled to 50000 positions for this run.\n",
      "49634 non-terminal positions remain after filtering.\n",
      "Running model.predict on 49634 positions…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Depth=3 Top-1: 100%|██████████| 49634/49634 [00:27<00:00, 1810.48pos/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Evaluated 49634 positions.\n",
      "=> Top-1 agreement at depth 3: 4934/49634 = 9.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Depth=3 Top-3: 100%|██████████| 49634/49634 [00:26<00:00, 1884.97pos/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Evaluated 49634 positions.\n",
      "=> Top-3 agreement at depth 3: 9974/49634 = 20.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ----------------------------------------------------------------\n",
    "STOCKFISH_PATH = r\"C:\\BPR\\Attempt2\\stockfishe\\stockfish-windows-x86-64-avx2.exe\"\n",
    "MAPPING_PATH   = \"full_move_mapping_1000.json\"       # serialized mapping\n",
    "MAX_SAMPLES    = 50000      # max FENs to evaluate\n",
    "BATCH_SIZE     = 512        # batch size for model predictions\n",
    "# --- Windows + Jupyter fix for subprocesses --------------------------------\n",
    "if hasattr(asyncio, \"WindowsProactorEventLoopPolicy\"):\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "\n",
    "# ---  Load trained model ---------------------------------------------------\n",
    "model = load_model(\"models/TF_20EPOCHS_WR1000_map.keras\")\n",
    "\n",
    "# ---  Load the canonical move mapping from JSON ----------------------------\n",
    "with open(\"full_move_mapping_1000.json\") as f:\n",
    "    raw = json.load(f)               # keys were dumped as strings\n",
    "# convert keys back to ints\n",
    "int_to_move = {int(k):v for k,v in raw.items()}\n",
    "move_to_int = {v: k for k, v in int_to_move.items()}\n",
    "\n",
    "# sanity-check: model outputs must match mapping size\n",
    "n_out = model.output_shape[-1]\n",
    "n_map = len(int_to_move)\n",
    "assert n_out == n_map, (\n",
    "    f\"⚠️  Mismatch: model has {n_out} outputs but mapping has {n_map} moves.\"\n",
    ")\n",
    "print(f\"✅ Loaded mapping with {n_map} moves → matches model outputs.\")\n",
    "\n",
    "# --- Setup Stockfish -------------------------------------------------------\n",
    "engine = chess.engine.SimpleEngine.popen_uci(STOCKFISH_PATH)\n",
    "\n",
    "# ---  Load & sample your test positions ------------------------------------\n",
    "test_fens = []\n",
    "with open(\"games.pgn\") as pgn:\n",
    "    while True:\n",
    "        game = chess.pgn.read_game(pgn)\n",
    "        if game is None:\n",
    "            break\n",
    "        board = game.board()\n",
    "        for move in game.mainline_moves():\n",
    "            board.push(move)\n",
    "            if board.fullmove_number >= 10 and board.fullmove_number % 5 == 0:\n",
    "                test_fens.append(board.fen())\n",
    "\n",
    "print(f\"Loaded {len(test_fens)} total positions from your PGN.\")\n",
    "\n",
    "if len(test_fens) > MAX_SAMPLES:\n",
    "    test_fens = random.sample(test_fens, MAX_SAMPLES)\n",
    "    print(f\"Down-sampled to {len(test_fens)} positions for this run.\")\n",
    "\n",
    "test_fens = [fen for fen in test_fens if not chess.Board(fen).is_game_over()]\n",
    "print(f\"{len(test_fens)} non-terminal positions remain after filtering.\")\n",
    "\n",
    "# ---  Batch model predictions ----------------------------------------------\n",
    "all_X = np.stack([board_to_matrix(chess.Board(fen)) for fen in test_fens])\n",
    "print(f\"Running model.predict on {len(test_fens)} positions…\")\n",
    "all_probs = model.predict(all_X, batch_size=BATCH_SIZE, verbose=0)\n",
    "\n",
    "# ---  Stockfish agreement loop with a single tqdm bar ----------------------\n",
    "def evaluate_agreement(fen_list, probs_list, depth=3, top_n=1):\n",
    "    correct = total = 0\n",
    "\n",
    "    for fen, probs in tqdm(zip(fen_list, probs_list),\n",
    "                           total=len(fen_list),\n",
    "                           desc=f\"Depth={depth} Top-{top_n}\",\n",
    "                           unit=\"pos\",\n",
    "                           dynamic_ncols=True,\n",
    "                           leave=True):\n",
    "        board = chess.Board(fen)\n",
    "\n",
    "        # Stockfish best move\n",
    "        result = engine.play(board, chess.engine.Limit(depth=depth))\n",
    "        if result.move is None:\n",
    "            continue\n",
    "        sf_move = result.move.uci()\n",
    "\n",
    "        # Our model’s top-n moves (only those in mapping)\n",
    "        ranked = np.argsort(probs)[::-1]\n",
    "        top_moves = [int_to_move[i] for i in ranked[:top_n]]\n",
    "\n",
    "        if sf_move in top_moves:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"No positions evaluated!\")\n",
    "        return 0.0\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"\\n=> Evaluated {total} positions.\")\n",
    "    print(f\"=> Top-{top_n} agreement at depth {depth}: \"\n",
    "          f\"{correct}/{total} = {acc*100:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "# ---  Run both Top-1 and Top-3 tests ---------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_agreement(test_fens, all_probs, depth=3, top_n=1)\n",
    "    evaluate_agreement(test_fens, all_probs, depth=3, top_n=3)\n",
    "    engine.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️  All sampled SF moves map to your model’s move set.\n"
     ]
    }
   ],
   "source": [
    "engine = chess.engine.SimpleEngine.popen_uci(STOCKFISH_PATH)\n",
    "# Sanity‐check A: SF moves vs. move index map\n",
    "missing = set()\n",
    "for fen in random.sample(test_fens, min(500, len(test_fens))):\n",
    "    board = chess.Board(fen)\n",
    "    result = engine.play(board, chess.engine.Limit(depth=1))\n",
    "    sf = result.move\n",
    "    if sf is None:\n",
    "        continue\n",
    "    sf_uci = sf.uci()\n",
    "    # If Stockfish’s move isn’t one of the moves your model knows about:\n",
    "    if sf_uci not in int_to_move.values():\n",
    "        missing.add(sf_uci)\n",
    "if missing:\n",
    "    print(\"⚠️  These SF moves are NOT in int_to_move:\\n\", missing)\n",
    "else:\n",
    "    print(\"✔️  All sampled SF moves map to your model’s move set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random‐legal Top-3 baseline: 16.56%\n"
     ]
    }
   ],
   "source": [
    "hits = []\n",
    "for fen in random.sample(test_fens, min(1000, len(test_fens))):\n",
    "    board = chess.Board(fen)\n",
    "    sf_res = engine.play(board, chess.engine.Limit(depth=1))\n",
    "    if sf_res.move is None:\n",
    "        continue\n",
    "    sf_move = sf_res.move\n",
    "\n",
    "    legal = list(board.legal_moves)\n",
    "    if len(legal) < 3:\n",
    "        continue\n",
    "\n",
    "    picks = random.sample(legal, 3)\n",
    "    hits.append(int(sf_move in picks))\n",
    "\n",
    "print(f\"Random‐legal Top-3 baseline: {statistics.mean(hits)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Keras model with output shape (None, 1884)\n",
      "→ Converting to ONNX…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rewriter <function rewrite_constant_fold at 0x000002435CCE5BC0>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ONNX model saved to export\\policy_fullmoves.onnx\n",
      "✅ Mapping JSON copied to export\\move_mapping.json\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "KERAS_MODEL_PATH = \"models/TF_20EPOCHS_WR1000_map.keras\"\n",
    "EXPORT_DIR       = \"export\"\n",
    "ONNX_PATH        = os.path.join(EXPORT_DIR, \"policy_fullmoves.onnx\")\n",
    "MAPPING_SRC      = \"full_move_mapping_1000.json\"\n",
    "MAPPING_DST      = os.path.join(EXPORT_DIR, \"move_mapping.json\")\n",
    "\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "# Load Keras model\n",
    "model = tf.keras.models.load_model(KERAS_MODEL_PATH)\n",
    "print(\"Loaded Keras model with output shape\", model.output_shape)\n",
    "\n",
    "# Wrap it in a tf.function with explicit input_signature\n",
    "# This tells tf2onnx what the input shape and dtype are.\n",
    "input_signature = [\n",
    "    tf.TensorSpec([None, 8, 8, 12], tf.float32, name=\"input\")\n",
    "]\n",
    "@tf.function(input_signature=input_signature)\n",
    "def model_fn(x):\n",
    "    # returns Tensor of shape [None, N_moves]\n",
    "    return model(x)\n",
    "\n",
    "# Convert to ONNX via from_function (now with input_signature)\n",
    "print(\"→ Converting to ONNX…\")\n",
    "model_proto, _ = tf2onnx.convert.from_function(\n",
    "    model_fn,\n",
    "    input_signature=input_signature,\n",
    "    opset=13,\n",
    "    output_path=ONNX_PATH\n",
    ")\n",
    "print(f\"✅ ONNX model saved to {ONNX_PATH}\")\n",
    "\n",
    "# Copy your move-mapping JSON next to the ONNX\n",
    "shutil.copyfile(MAPPING_SRC, MAPPING_DST)\n",
    "print(f\"✅ Mapping JSON copied to {MAPPING_DST}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
